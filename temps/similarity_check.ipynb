{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import gensim\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper stuff for tokenizing and get rid of stopwords\n",
    "stopwords_list = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the inputs\n",
    "\n",
    "# will change this line to get the goal word from user\n",
    "goal_word = ['sunshine']\n",
    "\n",
    "# will change this line to get the input from user\n",
    "input_sent = 'this is really, really something that i have personally thought about and i had a wonderful experience with john, said st. clair.'.lower()\n",
    "\n",
    "# will change this to get this from gpt2 out\n",
    "with open(r'gpt2_output.txt') as reader:\n",
    "    gpt2_output = reader.read().lower()\n",
    "    \n",
    "# ---------- next cell ------------------\n",
    "\n",
    "# text to sentences and sentences to words\n",
    "\n",
    "# tokenize the input sentence to a list\n",
    "input_sent_w2list = tokenizer.tokenize(input_sent)\n",
    "# and remove the stopwords\n",
    "input_sent_w2list = [word for word in input_sent_w2list if not(word in stopwords_list)]\n",
    "\n",
    "# tokenize the gpt2 output\n",
    "sent_list = tokenize.sent_tokenize(gpt2_output) # to sentences\n",
    "\n",
    "# define a list to store the gpt2 sentences, tokenized to list of words \n",
    "gpt2_w2list = sent_list.copy()\n",
    "\n",
    "for i in range(len(sent_list)): \n",
    "    # and to words\n",
    "    gpt2_w2list[i] = tokenizer.tokenize(gpt2_w2list[i])\n",
    "    # and finally get rid of the stopwords\n",
    "    gpt2_w2list[i] = [word for word in gpt2_w2list[i] if not(word in stopwords_list)]\n",
    "    \n",
    "\n",
    "# ---------- next cell ------------------\n",
    "\n",
    "# compare the similarity between each sentences of gpt2 and both input and gpt2\n",
    "\n",
    "# create an empty list to record the similarity scores for all gpt2-generated sentences\n",
    "score_list = []\n",
    "\n",
    "for sent in gpt2_w2list:\n",
    "    # calculate the similarity to the input sentence\n",
    "    in_sim = model.n_similarity(input_sent_w2list, sent)\n",
    "    # calculate the similarity to the goal word\n",
    "    gl_sim = model.n_similarity(goal_word, sent)\n",
    "    # sum over both scores and add it to the score_list\n",
    "    score_list.append(in_sim + gl_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the similarity between the goal word and each sentences of gpt2\n",
    "\n",
    "# create an empty list to record the similarity scores for all gpt2-generated sentences\n",
    "score_list_2output = []\n",
    "\n",
    "for sent in gpt2_w2list:\n",
    "    # calculate the similarity\n",
    "    score_list.append(model.n_similarity(input_sent_w2list, sent))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when her brother got home, he just told me to be good for today as well, he didn''t like it, and he was pretty mad that the sun was setting as well, because he wanted it to be a really beautiful day for us.\n"
     ]
    }
   ],
   "source": [
    "# find the max score and return the corresponding sentence\n",
    "\n",
    "print(sent_list[score_list.index(max(score_list))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
